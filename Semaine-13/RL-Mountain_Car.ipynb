{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semaine 13 - Reinforcement Learning, Q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'exercice de cette semaine, nous utiliserons le module *Gym* d'OpenAI. Gym implémente divers environnements compatibles avec des problèmes de RL pour permettre à la communauté scientifique de s'y entraîner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le lien vers la documentation de *Gym*:   https://gym.openai.com/docs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /sgoinfre/goinfre/Perso/hben-yah/miniconda3/lib/python3.7/site-packages (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /sgoinfre/goinfre/Perso/hben-yah/miniconda3/lib/python3.7/site-packages (from gym) (1.15.4)\n",
      "Requirement already satisfied: scipy in /sgoinfre/goinfre/Perso/hben-yah/miniconda3/lib/python3.7/site-packages (from gym) (1.2.1)\n",
      "Requirement already satisfied: pyglet>=1.2.0 in /sgoinfre/goinfre/Perso/hben-yah/miniconda3/lib/python3.7/site-packages (from gym) (1.3.2)\n",
      "Requirement already satisfied: requests>=2.0 in /sgoinfre/goinfre/Perso/hben-yah/miniconda3/lib/python3.7/site-packages (from gym) (2.21.0)\n",
      "Requirement already satisfied: six in /sgoinfre/goinfre/Perso/hben-yah/miniconda3/lib/python3.7/site-packages (from gym) (1.12.0)\n",
      "Requirement already satisfied: future in /sgoinfre/goinfre/Perso/hben-yah/miniconda3/lib/python3.7/site-packages (from pyglet>=1.2.0->gym) (0.17.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /sgoinfre/goinfre/Perso/hben-yah/miniconda3/lib/python3.7/site-packages (from requests>=2.0->gym) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /sgoinfre/goinfre/Perso/hben-yah/miniconda3/lib/python3.7/site-packages (from requests>=2.0->gym) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /sgoinfre/goinfre/Perso/hben-yah/miniconda3/lib/python3.7/site-packages (from requests>=2.0->gym) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sgoinfre/goinfre/Perso/hben-yah/miniconda3/lib/python3.7/site-packages (from requests>=2.0->gym) (2018.11.29)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'environnement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans MountainCar, il faire à apprendre au pilote de la voiture comment monter au sommet de la montagne. Mais le moteur n'a pas assez de puissance pour y arriver d'un coup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "env.reset()\n",
    "for timestep in range(200):\n",
    "    env.render()\n",
    "    env.step(2)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le pilote dispose de 3 actions possibles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testez différentes valeurs pour la variable \"action\" afin de découvrir comment est encodé le choix de l'action pour le passer à l'environnement au travers de la méthode step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 2\n",
    "\n",
    "env = gym.make('MountainCar-v0')\n",
    "env.seed(42)\n",
    "env.reset()\n",
    "for timestep in range(200):\n",
    "    env.render()\n",
    "    env.step(action)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les observations et les états"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'environnement fournit à l'agent deux valeurs continues comme observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(2,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une des valeurs correspond à la position, l'autre à la vitesse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les observations sont renvoyées par deux différentes méthodes de l'environnement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.50313229  0.        ]\n",
      "[-0.50228569  0.0008466 ]\n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "print(observation)\n",
    "observation, reward, done, info = env.step(action)\n",
    "print(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour faire du q-learning, il faut un nombre fini d'état, donc nos valeurs continues doivent devenir discrètes. Écrivez une fonction qui divise l'échelle de variation de chaque valeur en 20 segments égaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_segments = 20\n",
    "\n",
    "def obs_to_state(obs):\n",
    "    min_position, min_speed = env.observation_space.low\n",
    "    max_position, max_speed = env.observation_space.high\n",
    "    position, speed = obs\n",
    "    \n",
    "    position_delta = (max_position - min_position) / n_segments\n",
    "    speed_delta = (max_speed - min_speed) / n_segments\n",
    "    position_segm = int((position-min_position)/position_delta)\n",
    "    speed_segm = int((speed-min_speed)/speed_delta)\n",
    "    \n",
    "    state = position_segm, speed_segm\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testez votre fonction: Faites-lui transformer l'état renvoyé par env.reset()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 10)\n"
     ]
    }
   ],
   "source": [
    "print(obs_to_state(env.reset()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'agent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par souci de simplicité, nous n'allons pas implémenter l'agent comme objet, mais néanmoins nous implémenterons sa Policy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créez une table de q-valeurs qui peut contenir une q-valeur distincte pour chaque action possible, dans tous les états imaginables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.25091976  0.90142861  0.46398788]\n",
      "  [ 0.19731697 -0.68796272 -0.68801096]\n",
      "  [-0.88383278  0.73235229  0.20223002]\n",
      "  ...\n",
      "  [ 0.55026565  0.87899788  0.7896547 ]\n",
      "  [ 0.19579996  0.84374847 -0.823015  ]\n",
      "  [-0.60803428 -0.90954542 -0.34933934]]\n",
      "\n",
      " [[-0.22264542 -0.45730194  0.65747502]\n",
      "  [-0.28649335 -0.43813098  0.08539217]\n",
      "  [-0.71815155  0.60439396 -0.85089871]\n",
      "  ...\n",
      "  [-0.67755743  0.8593953   0.61624076]\n",
      "  [ 0.26680751  0.74292118  0.60734415]\n",
      "  [-0.62685988  0.785118    0.07868448]]\n",
      "\n",
      " [[ 0.61488031  0.7921826  -0.36399305]\n",
      "  [-0.77989615 -0.54412967 -0.14578442]\n",
      "  [ 0.63602953  0.72146117 -0.98609574]\n",
      "  ...\n",
      "  [-0.96682434  0.02418612 -0.54700845]\n",
      "  [ 0.29034558 -0.65126714  0.38187548]\n",
      "  [-0.22652931  0.87345998 -0.72495811]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.39484053 -0.40530199  0.84879239]\n",
      "  [ 0.94211649  0.88853298 -0.05157157]\n",
      "  [ 0.7240853   0.6890988  -0.36179905]\n",
      "  ...\n",
      "  [-0.5327845  -0.91581362 -0.96425213]\n",
      "  [ 0.97544478 -0.14445373 -0.23134671]\n",
      "  [ 0.35929457 -0.56349222  0.89992237]]\n",
      "\n",
      " [[ 0.57269003 -0.821178   -0.16483845]\n",
      "  [ 0.75823662  0.88946404 -0.06519698]\n",
      "  [ 0.22682278 -0.66593211  0.98233725]\n",
      "  ...\n",
      "  [-0.00824853 -0.83790757 -0.5596336 ]\n",
      "  [ 0.36651753 -0.84773828  0.70241383]\n",
      "  [-0.00970695 -0.03882685  0.18481557]]\n",
      "\n",
      " [[ 0.64936193 -0.30438158  0.35603231]\n",
      "  [ 0.13146393 -0.46594346  0.75725997]\n",
      "  [ 0.59485204  0.31690367  0.70116346]\n",
      "  ...\n",
      "  [ 0.16434092 -0.30823389  0.24183104]\n",
      "  [-0.90851593  0.74307361  0.94697794]\n",
      "  [ 0.93775571  0.49930366 -0.73982752]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "dimensions = (n_segments, n_segments, env.action_space.n) \n",
    "q_table = np.random.uniform(low=-1, high=1, size=dimensions)\n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentez la Greedy policy, qui utilise la q_table pour décider de la meilleure action à choisir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_policy(state):\n",
    "    action = np.argmax(q_table[state])\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentez maintenant la Epsilon-greedy policy, qui ajoute une probabilité *epsilon* que l'action soit choisie aléatoirement  \n",
    "_**Indice:**_ np.random.choice(n) choisira aléatoirement un nombre de 0 à n exclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(state, epsilon):\n",
    "    if np.random.rand(1) < epsilon:\n",
    "        action = np.random.choice(env.action_space.n)\n",
    "    else:\n",
    "        action = greedy_policy(state)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #100 -- Average reward = -200.0\n",
      "Iteration #200 -- Average reward = -200.0\n",
      "Iteration #300 -- Average reward = -200.0\n",
      "Iteration #400 -- Average reward = -200.0\n",
      "Iteration #500 -- Average reward = -200.0\n",
      "Iteration #600 -- Average reward = -200.0\n",
      "Iteration #700 -- Average reward = -200.0\n",
      "Iteration #800 -- Average reward = -200.0\n",
      "Iteration #900 -- Average reward = -200.0\n",
      "Iteration #1000 -- Average reward = -200.0\n",
      "Iteration #1100 -- Average reward = -200.0\n",
      "Iteration #1200 -- Average reward = -200.0\n",
      "Iteration #1300 -- Average reward = -200.0\n",
      "Iteration #1400 -- Average reward = -200.0\n",
      "Iteration #1500 -- Average reward = -200.0\n",
      "Iteration #1600 -- Average reward = -200.0\n",
      "Iteration #1700 -- Average reward = -200.0\n",
      "Iteration #1800 -- Average reward = -200.0\n",
      "Iteration #1900 -- Average reward = -200.0\n",
      "Iteration #2000 -- Average reward = -200.0\n",
      "Iteration #2100 -- Average reward = -200.0\n",
      "Iteration #2200 -- Average reward = -200.0\n",
      "Iteration #2300 -- Average reward = -200.0\n",
      "Iteration #2400 -- Average reward = -200.0\n",
      "Iteration #2500 -- Average reward = -200.0\n",
      "Iteration #2600 -- Average reward = -200.0\n",
      "Iteration #2700 -- Average reward = -200.0\n",
      "Iteration #2800 -- Average reward = -200.0\n",
      "Iteration #2900 -- Average reward = -200.0\n",
      "Iteration #3000 -- Average reward = -199.29\n",
      "Iteration #3100 -- Average reward = -199.64\n",
      "Iteration #3200 -- Average reward = -197.19\n",
      "Iteration #3300 -- Average reward = -197.13\n",
      "Iteration #3400 -- Average reward = -191.48\n",
      "Iteration #3500 -- Average reward = -194.33\n",
      "Iteration #3600 -- Average reward = -194.26\n",
      "Iteration #3700 -- Average reward = -198.18\n",
      "Iteration #3800 -- Average reward = -193.23\n",
      "Iteration #3900 -- Average reward = -193.22\n",
      "Iteration #4000 -- Average reward = -192.72\n",
      "Iteration #4100 -- Average reward = -180.85\n",
      "Iteration #4200 -- Average reward = -190.39\n",
      "Iteration #4300 -- Average reward = -185.42\n",
      "Iteration #4400 -- Average reward = -188.74\n",
      "Iteration #4500 -- Average reward = -186.61\n",
      "Iteration #4600 -- Average reward = -181.63\n",
      "Iteration #4700 -- Average reward = -182.94\n",
      "Iteration #4800 -- Average reward = -175.06\n",
      "Iteration #4900 -- Average reward = -181.45\n",
      "Iteration #5000 -- Average reward = -182.63\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "episodes_max = 5000\n",
    "lr = 0.2\n",
    "gamma = 1.1\n",
    "\n",
    "# Epsilon will diminish over the episodes to increase exploitation\n",
    "start_epsilon = 0.8\n",
    "final_epsilon = 0\n",
    "epsilon_reduction = (start_epsilon - final_epsilon) / episodes_max\n",
    "epsilon = start_epsilon\n",
    "\n",
    "reward_list = []\n",
    "avg_reward_list = []\n",
    "\n",
    "# Train for 'episodes_max' episodes\n",
    "for episode in range(episodes_max):\n",
    "    \n",
    "    # Initialize parameters of the episode\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    state1 = obs_to_state(env.reset())\n",
    "    \n",
    "    # Each episode runs for a maximum of 200 timesteps, at whith point the Environment returns done = True\n",
    "    while done is False:\n",
    "        \n",
    "        # The agent chooses an action\n",
    "        action = epsilon_greedy_policy(state1, epsilon)\n",
    "        \n",
    "        # The action is given to the environment, which returns a new state, a reward, and some other info\n",
    "        # (see documentation https://gym.openai.com/docs/)\n",
    "    \n",
    "        observation, reward, done, info = env.step(action)\n",
    "        state2 = obs_to_state(observation)\n",
    "        \n",
    "        total_reward += reward\n",
    "        \n",
    "        # Update q_table\n",
    "        if done:\n",
    "            \"\"\"Quelle est la q-valeur de la toute dernière action???\"\"\"\n",
    "            q_table[state1][action] = reward\n",
    "        else:\n",
    "            \"\"\"Hmmmm... On dirait qu'on va s'amuser avec l'équation de Bellman!!\"\"\"\n",
    "            q_table[state1][action] = (1 - lr) * q_table[state1][action] + lr * (reward + gamma * max(q_table[state2]))\n",
    "        \n",
    "        # The new state becomes state1 of the next loop\n",
    "        state1 = state2\n",
    "    \n",
    "    # Epsilon decay\n",
    "    epsilon -= epsilon_reduction\n",
    "    \n",
    "    # Display rewards\n",
    "    reward_list.append(total_reward)\n",
    "    if (episode + 1) % 100 == 0:\n",
    "        avg_reward = np.mean(reward_list)\n",
    "        avg_reward_list.append(avg_reward)\n",
    "        reward_list = []\n",
    "        print('Iteration #{} -- Average reward = {}'.format(episode+1, avg_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La mise à l'épreuve "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut maintenant voir notre agent en action avec la Policy optimale. Quelle fonction utilisera-t-on pour sélectionner chaque action?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "state = obs_to_state(env.reset())\n",
    "done = False\n",
    "while done is False:\n",
    "    env.render()\n",
    "    action = greedy_policy(state)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    state = obs_to_state(obs)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évolution de l'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un petit graphique pour voir l'évolution du Return moyen de chaque tranche de 100 épisodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(100*(np.arange(len(avg_reward_list)) + 1), avg_reward_list)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Average Reward')\n",
    "plt.title('Average Reward vs Episodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
